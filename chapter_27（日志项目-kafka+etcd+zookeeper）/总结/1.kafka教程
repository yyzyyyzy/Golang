Broker : 部署了kafka实例的服务器节点
Topic(主题) : 消息的主题/消息的分类，用来保存数据的地方
Partition(分区) : topic的分区，表现形式就是文件夹，目的是做负载，提高kafka的吞吐量
Producer : 负责发布消息到Kafka broker
Consumer : 消息消费者，向Kafka broker读取消息的客户端。
Consumer Group（消费者群组） : 每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。
offset 偏移量： 是kafka用来确定消息是否被消费过的标识，在kafka内部体现就是一个递增的数字
Replication : 主分区故障，副本分区上位

运行流程：
1.生产者从kafka集群获取分区leader信息
2.生产者发送消息给leader
3.leader将消息写入本地磁盘
4.follower从leader拉取消息数据
5.follower将消息写入本地磁盘后再向leader发送ACK
6.leader收到所有的follower的ACK后向生产者发送ACK


安装流程：
安装java jdk，配置环境变量
kafka下载解压
zookeeper下载解压

①先启动zookeeper：
1.复制conf/zoo_sample.conf --> zoo.conf
2.根目录下新建log和data文件
3.配置zoo.conf:
    dataDir=D:/zookeeper/data
    dataLogDir=D:/zookeeper/log
4.打开window/zkServer.cmd

②再启动kafka
1.新建kafkalog文件
2.复制zookeeper.properties为zoo.properties
3.配置config/server.properties：
    log.dirs=D:/kafka/kafkalog
4.启动kafka，cmd输入bin\windows\kafka-server-start.bat config\server.properties

③golang使用sarma向kafka消息队列发消息
1.使用go module环境，配置goproxy
2.go get github.com/Shopify/sarama （windows只能使用1.19以下版本）
3.go mod init kafkademo：
    require github.com/Shopify/sarama v1.19.0
4.go mod download

④cmd从kafka取消息
1.数据存储在kafka的kafkalog/web_log文件夹内
1.bin\windows\kafka-console-consumer.bat --bootstrap-server 127.0.0.1:9092 --topic web_log --from-beginning
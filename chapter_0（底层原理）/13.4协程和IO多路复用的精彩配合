①
多线程的缺点：（一是系统线程会占用非常多的内存空间，二是过多的线程切换会占用大量的系统时间）
1. 涉及到同步锁
2. 涉及到线程阻塞状态和可运行状态之间的切换
3. 涉及到线程上下文的切换

所以，在有大量IO操作业务的情况下，我们采用协程替换线程，可以到达很好的效果，一是降低了系统内存，二是减少了系统切换开销，因此系统的性能也会提升。
     在协程中尽量不要调用阻塞IO的方法，比如打印，读取文件，Socket接口等，除非改为异步调用的方式，并且协程只有在IO密集型的任务中才会发挥作用。


②：
操作系统的进程控制信息中“打开文件描述符表”记录了进程打开的文件、创建的socket，socket所有操作都由操作系统的系统调用来完成
每创建一个socket就会在“打开文件描述符表”中增加一条记录，返回给应用程序一个socket描述符，用于识别不同的socket；
每个TCP socket创建时，操作系统会再内核空间分配一个读缓冲区和写缓冲区：
1.要获得响应数据，就需要从读缓冲区拷贝到用户空间的接收数据区
2.要发送数据，就需要从发送数据区拷贝到写缓冲区

所以会出现用户读取数据时，读缓冲区为空，用户发送数据时，写缓冲区空间不足的情况。
解决方法：
1.阻塞式IO：让出CPU进入等待队列，等待socket就绪，再次通过时间片轮转，继续执行socket。
缺点：每处理一个socket就占用一个线程，高并发场景下会加剧调度开销

2.非阻塞式IO：不让出CPU，频繁检查socket是否就绪（忙等待）
缺点：很难把握轮询的间隔时间，容易空耗CPU，加剧响应延迟

3.IO多路复用：操作系统将需要等待的socket加入监听集合，通过一次系统调用，同时监听多个socket，有socket就绪，就可以逐个处理
            既不用等待某个socket阻塞，也不会陷入忙等待
            linux提供三种IO多路复用的方式select/epoll/poll

            select
            1)函数原型：（对读事件感兴趣的就传入第二个参数，写就第三个，异常就第四个）
                int select(int maxfdpl,
                fd_set *readset, //fd_set是unsigned long数组，共16个元素，每一位对应一个fd ==>（16 * 64 = 1024）监听1024个事件
                fd_set *writeset,
                fd_set *exceptset,
                struct timeval *timeout);
            2)过程：
                  该函数会等待多个I/O事件(比如读就绪，写)的任何一个发生，并且只要有一个事件发生，select线程就会执行，没有任何事件发生则阻塞
                  1.使用copy_from_user将fd_set从用户空间拷贝到内核空间
                  2.注册回调函数__pollwait
                  3.遍历所有fd，调用其对应的poll方法：
                              对于socket，这个poll方法是sock_poll，sock_poll根据情况会用到tcp_poll，udp_poll或者datagram_poll
                              tcp_poll的核心实现就是__pollwait，也就是上面注册的回调函数，
                              主要工作是把当前进程挂到设备的等待队列中(但不代表睡眠)，不同设备有不同的等待队列，
                              在设备收到一条信息(来自网络设备或磁盘设备)，会唤醒设备等待队列上的睡眠进程
                  4.poll方法会返回一个描述读写操作是否就绪的mask掩码，根据它给fd_set赋值
                  5.如果遍历完也还没有发现一个已经就绪的fd，就调用schedule_timeout使进程睡眠，然后等可读写了或者又过了一段时间之后再醒过来，
                    如果超过一定时间还没被唤醒，则醒来重新遍历循环这个过程
                  6.把fd_set从内核空间拷贝到用户空间
            3)缺点：
                  1.每次调用select都要将fd_set从用户空间拷贝到内核空间
                  2.且都要在内核遍历fd_set，开销很大
                  3.select支持的fd数量非常少，默认1024

            poll
            1)函数原型：
                int poll(
                struct pollfd *fds,
                nfds_t nfds,
                int timeout);
            2)过程：
            和select非常类似，只是poll用pollfd，类似select的fd_set，但它没有最大连接数的限制，因为基于链表实现

            epoll
            epoll是对select和poll的改进，克服了上面的三个缺点，
            select和poll都只提供了一个函数，而epoll提供了三个函数：
                    1.epoll_create：创建一个epoll句柄
                    2.epoll_ctl：注册要监听的事件类型
                    3.epoll_wait：等待事件发生
            对于第一个缺点，epoll_ctl中指定EPOLL_CTL_ADD注册新的事件到epoll句柄中时把fd拷贝进内核，
            保证了每个fd只会被拷贝一次（epoll_ctl每次仅处理一个fd）

            对于第二个缺点，epoll只在epoll_ctl把当前线程放入等待队列并为每个fd指定回调函数，
            等事件发生就会调用这个回调函数，这个回调函数会把就绪的fd放入就绪链表
            （epoll_wait和select一样也是睡一下判断一下，但epoll_wait只需要判断链表是否为空就可以了，
            主要都是靠回调自己干活，性能大大提升(主要是减少了自己轮询查看的成本)）

            对于第三个缺点，epoll支持的FD是最大可以打开的文件数目，在1GB内存的机器上大约是十万（用红黑树管理）

IO多路复用epoll改进后仍存在的问题：
1.一个socket可读，但是只读到了半条请求，需要再次等待socket可读，在处理下一个socket前，需要保存socket的执行现场，直到可读时恢复上次保存的现场；
  所以在使用IO多路复用实现业务逻辑时，需要频繁保存和恢复执行现场，业务逻辑会较为复杂

协程和IO多路复用的配合：（让处理过程面向协程调度）
1.如果是用于监听端口的fd就绪了，就建立连接创建新的fd，交给协程负责，协程执行入口指向业务处理函数入口，
业务处理过程中，需要等待时就注册IO事件然后让出，让执行权切换到该协程继续执行
2.其他等待IO事件的fd就绪，只需要恢复关联的协程即可，协程拥有自己的栈，保存和恢复执行现场都很容易，这样IO多路复用事件的逻辑循环就和具体业务解耦了
3.可以把read、write、connect函数包装，在其实现IO事件注册和主动让出，在业务逻辑层面使用包装后的函数按照常规的顺序编程，这些包装函数，在需要等待时，
会注册IO事件，然后让出协程，这样实现业务逻辑时，不用担心保存和恢复现场的问题

**示例回答**：
> 总结来说，`select`具有跨平台支持，但性能较差，适合文件描述符较少的场景；`poll`解决了`select`的文件描述符数量限制，但性能仍然较差；`epoll`具有高性能，适合高并发场景，但仅支持Linux。

---

### **完整示例回答**
> `poll`、`epoll`和`select`都是I/O多路复用机制，用于同时监控多个文件描述符的状态（如可读、可写或异常）。它们的主要目的是在单线程或少量线程中高效处理大量I/O操作，避免为每个连接创建线程的开销。  
>  
> **`select`**是最早的I/O多路复用机制，具有跨平台支持的特点。它通过`fd_set`位图管理文件描述符，但有以下局限性：文件描述符数量有限（通常1024个），每次调用需要将`fd_set`从用户态拷贝到内核态，性能较差，且需要遍历所有文件描述符来检查状态，时间复杂度为O(n)。  
>  
> **`poll`**是对`select`的改进，使用`pollfd`数组管理文件描述符，没有数量限制，且不需要每次调用时重置文件描述符集合。但它仍然需要遍历所有文件描述符来检查状态，时间复杂度为O(n)，在文件描述符较多时性能仍然较差。  
>  
> **`epoll`**是Linux特有的I/O多路复用机制，具有以下优势：文件描述符数量没有限制，不需要每次调用时拷贝文件描述符集合，仅返回就绪的文件描述符，时间复杂度为O(1)，且支持边缘触发（ET）和水平触发（LT）模式，边缘触发模式可以减少事件通知次数，提高性能。  
>  
> 在Go语言中，`net`包底层使用了高效的I/O多路复用机制，如Linux下的`epoll`或BSD下的`kqueue`。Go的运行时调度器与这些机制结合，实现了高效的Goroutine调度。例如，当一个Goroutine等待I/O时，调度器会将其挂起，并切换到其他Goroutine执行，从而充分利用CPU资源。  
>  
> 总结来说，`select`具有跨平台支持，但性能较差，适合文件描述符较少的场景；`poll`解决了`select`的文件描述符数量限制，但性能仍然较差；`epoll`具有高性能，适合高并发场景，但仅支持Linux。

①多进程/多线程问题：
1.线程上下文切换，由于中断处理，多任务处理，用户态切换等原因会导致 CPU 从一个线程切换到另一个线程，切换过程需要保存当前进程的状态并恢复另一个进程的状态。
2.上下文切换的代价是高昂的，因为在核心上交换线程会花费很多时间。

②协程（co-routine）引发的问题：
N:1 无法利用多个CPU，出现阻塞的问题
1:1 和多进程/多线程相同，切换成本较高
M:N 能够利用多核，需要对调度器进行优化！

③调度器的优化：
goroutine内存占用：几kb，可以大量开辟
                 灵活调度，切换成本低

④老调度器缺点：
1.创建销毁调度G需要M获取锁，导致锁竞争
2.M转移G会造成延迟和额外的系统负载
3.系统调用（CPU在M之间的切换）导致了频繁的线程阻塞和取消阻塞操作增加了系统开销

⑤GPM模型简介：
GMP：G协程（用户态线程）、M线程（内核态线程）、P处理器

全局队列：存放等待的G，优先放在本地队列，超过256个再放在全局队列
本地队列：存放等待的G（不能超过256个G）

P列表在程序启动时创建，最多有GOMAXPROCS个，可以通过runtime.GOMAXPROCS()设置，默认值为逻辑CPU数量
M列表表示当前操作系统分配到当前Go程序的内核线程数，最大是10000个，会动态分配线程数（M阻塞，创建一个新M，M空闲，gc回收）

⑥调度器的设计策略：
1.复用线程：
  1)work stealing机制：
                    M1线程的G1在工作，G2、G3在P1的本地队列中等待执行，M2线程处于空闲状态，那么P2会从P1的本地队列中偷取一个G3
  2)hand off机制：
               M1线程的G1在工作，G2在P1的本地队列中等待执行，M2线程偷取一个G3即将执行G3，此时G1阻塞，那么会再次创建/唤醒一个M3线程
               把阻塞的G1留给M1线程，P1和P1本地队列中的G2迁移到M3线程，不耽误G2的执行
2.利用并行
  1)GOMAXPROCS限定P的个数
3.抢占
  1)co-routine的抢占：第一条co-routine和CPU绑定，如果此时有另一条co-routine需要执行，那么需要等待第一条主动释放，第二条才能执行
  2)goroutine的抢占：每个goroutine运行绑定CPU 10ms，不管上一个goroutine是否主动释放，下一条都会抢占CPU
4.全局G队列
  1)可以从全局队列中使用work stealing机制偷取全局队列中的goroutine。

⑦go func()的运行过程：
1.go func()创建一个G1，把G1加入到P1的本地队列，若本地队列满了，就放到全局队列中
2.M1线程通过P1从本地队列中获取G，若本地队列为空，1.就从全局队列中获取；2.从其他P2...Pn的本地队列中偷取G（work stealing）
3.M1调度G1，执行G1.func函数，时间片超时则将G1返回给M1的本地队列的尾部，循环重复步骤3，直到G1执行完毕
  如果执行G.func出现阻塞，会创建一个新的线程M，接管M1线程本地队列中的其他协程，M1和G在一边继续等待阻塞结束，再决定M1和G继续执行还是GC (hand off)

⑧调度器的生命周期
M0：
M0是进程编号为0的主线程
M0保存在runtime.m中，不需要堆分配
M0负责执行初始化操作和启动第一个G
M0启动了第一个G之后就和其他线程一样了
G0：
每次启动一个M，第一个创建的goroutine就是G0
G0负责调度其他的G
G0不指向任何可执行的函数
每个M都有一个自己的G0
在调度或系统调用时使用M会切换到G0的栈空间
M0的G0会放在全局队列

package main

import "fmt"

func main() {
    fmt.Println("hello world")
}

hello world文件的运行流程：
1.创建一个M0和G0，对GOMAXPROCS进行初始化，P列表个数初步确定，初始化P的本地队列和全局队列
2.创建main goroutine，MO和G0解绑，main goroutine放入P1的本地队列，M0调度main goroutine，执行main goroutine
3.main goroutine执行完成后，调用exit函数，main goroutine消失

ps：
    GPM针对不同调度场景的应对全过程：

    场景一：G1创建G3（M1、M2线程绑定P1、P2，P1、P2分别正在执行G1、G2，P1、P2本地队列为空）
    1.G3的创建需要满足局部性原理（时间局部性和空间局部性），G1创建G3时，优先创建在G1所在的线程M1上，所以将G3放入P1的本地队列中。

    场景二：G1执行完毕（P1的本地队列有G2待执行，M2线程的P2的本地队列中有G4待执行）
    1.G1执行完毕后，调用goexit函数，G0使用schedule函数调度，优先取M1线程的本地队列中的G2执行，而不是work stealing偷M2线程的G4

    场景三：G1开辟了过多的G（P1本地队列中最多存4个G，G1需要创建6个G）
    1.前4个G（G2、G3、G4、G5）加入当前的本地队列中，P1本地队列已满，那么会对本地队列做对半的分割，然后将G2、G3顺序打乱，和溢出的G6、G7放入全局队列中
      此时本地队列未满，G7可以放入本地队列中

    场景四：唤醒正在休眠的M（P1本地队列有G4、G5、G7，全局队列中有G2、G6、G3）
    1.G2创建G7，此时会从休眠线程队列唤醒一个M2线程，M2执行G0，本地队列为空（自旋线程：不断寻找G）

    场景五：被唤醒的M2从全局队列中批量获取G
    1.M2自旋线程优先从全局队列获取G，获取的个数n = min(len(GQ/GOMAXPROCS + 1, len(GQ/2)))若全局队列为空，再work stealing偷取别的线程的G，
    从全局队列取G到本地队列是GPM模型内部的负载均衡

    场景六：M2从M1中偷取G（P1本地队列有G4、G5、G7，全局队列中有G2、G6、G3）
    1.M2自旋线程优先从全局队列获取G，G2、G6、G3全部获取完成并执行之后，M2再次执行G0，本地队列为空，重新成为了自旋线程。
    2.M2work stealing偷取M1本地队列的后1/2的所有线程，G7加入M2的本地队列，执行

    场景七：自旋线程的最大数量限制：自旋线程+执行线程 <= GOMAXPROCS

    场景八：M1本地队列为空，正在执行G1、M2本地队列有G3，正在执行G2，M3、M4为自旋线程，M5、M6为休眠线程
    1.M2的G2执行发生阻塞，M2和G2等待阻塞，P2重新绑定M5执行G3（自旋线程是抢占G，而不是抢占P）

    场景九：在场景八的基础上，M2和G2不再阻塞了
    1.M2会记录之前绑定的P2调度器，优先获取P2，P2已经绑定，抢占失败，寻找空闲的P队列，寻找失败，G2加入到全局队列中，等待自旋线程抢占，M2休眠

------------------------------------------------------------------------------------------------------------------------
GPM模型：
1.包括了GPM（G协程（用户态线程）、M线程（内核态线程）、P处理器）、全局队列、本地队列
2.全局队列和本地队列都用来存放等待的G，如果超过256个，那么就放在全局队列，没超过就放在本地队列中
3.P的个数和M的个数：
    P列表在程序启动时创建，最多有GOMAXPROCS个，可以通过runtime.GOMAXPROCS()设置，默认值为逻辑CPU数量
    M列表表示当前操作系统分配到当前Go程序的内核线程数，最大是10000个，会动态分配线程数（M阻塞，创建一个新M，M空闲，gc回收）

4.调度器的设计策略：
    1.复用线程：
      1)work stealing机制：
                        M1线程的G1在工作，G2、G3在P1的本地队列中等待执行，M2线程处于空闲状态，那么P2会从P1的本地队列中偷取一个G3
      2)hand off机制：
                   M1线程的G1在工作，G2在P1的本地队列中等待执行，M2线程偷取一个G3即将执行G3，此时G1阻塞，那么会再次创建/唤醒一个M3线程
                   把阻塞的G1留给M1线程，P1和P1本地队列中的G2迁移到M3线程，不耽误G2的执行
    2.利用并行
      1)GOMAXPROCS限定P的个数
    3.抢占
      1)co-routine的抢占：第一条co-routine和CPU绑定，如果此时有另一条co-routine需要执行，那么需要等待第一条主动释放，第二条才能执行
      2)goroutine的抢占：每个goroutine运行绑定CPU 10ms，不管上一个goroutine是否主动释放，下一条都会抢占CPU
    4.全局G队列
      1)可以从全局队列中使用work stealing机制偷取全局队列中的goroutine。

老调度器缺点：
    1.创建销毁调度G需要M获取锁，导致锁竞争
    2.M转移G会造成延迟和额外的系统负载
    3.系统调用（CPU在M之间的切换）导致了频繁的线程阻塞和取消阻塞操作增加了系统开销